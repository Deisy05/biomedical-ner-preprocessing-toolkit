import os
import json
from collections import defaultdict
import datetime

def normalizar_texto(texto):
    return ' '.join(texto)
    #return ' '.join(texto).lower()

def eliminar_duplicados_automaticamente(carpeta_base):
    sentencias = defaultdict(list)  # clave: sentencia -> lista de (ruta, l√≠nea, entrada_completa)
    print(f"üîç Buscando duplicados en: {carpeta_base}")
    
    # Paso 1: Recopilar todas las sentencias y sus ubicaciones
    archivos_procesados = 0
    lineas_procesadas = 0
    
    for root, _, files in os.walk(carpeta_base):
        for archivo in files:
            if archivo.endswith('.json'):
                ruta = os.path.join(root, archivo)
                try:
                    with open(ruta, 'r', encoding='utf-8') as f:
                        lineas = f.readlines()
                        for num_linea, linea in enumerate(lineas, start=1):
                            if not linea.strip():
                                continue
                            try:
                                entrada = json.loads(linea)
                                clave = normalizar_texto(entrada['sentencia'])
                                sentencias[clave].append((ruta, num_linea, linea.strip()))
                                lineas_procesadas += 1
                            except json.JSONDecodeError as e:
                                print(f"[ERROR] JSON mal formado en {ruta}, l√≠nea {num_linea}: {e}")
                except Exception as e:
                    print(f"[ERROR] No se pudo leer {ruta}: {e}")
                archivos_procesados += 1
    
    print(f"‚úÖ Procesados {archivos_procesados} archivos con {lineas_procesadas} l√≠neas JSON.")
    
    # Paso 2: Filtrar las sentencias que aparecen en m√°s de un archivo o en varias l√≠neas
    duplicadas = {s: ubicaciones for s, ubicaciones in sentencias.items() if len(ubicaciones) > 1}

    if not duplicadas:
        print("‚úÖ No se encontraron sentencias duplicadas entre archivos.")
        return

    # Paso 3: Organizar las eliminaciones (autom√°ticamente conserva la primera ocurrencia)
    print(f"üîÅ Se encontraron {len(duplicadas)} sentencias duplicadas.")
    
    # Agrupar por archivo para minimizar el n√∫mero de operaciones de escritura
    cambios_por_archivo = defaultdict(list)
    total_a_eliminar = 0
    
    # Para el reporte
    reporte = []
    
    for sentencia, ocurrencias in duplicadas.items():
        conservar = ocurrencias[0]  # Conservamos la primera ocurrencia
        eliminar = ocurrencias[1:]  # Eliminamos las dem√°s
        
        # Crear entradas para el reporte
        for archivo, linea, contenido in eliminar:
            reporte.append({
                "archivo": archivo,
                "linea": linea,
                "contenido": contenido,
                "conservada_en": f"{conservar[0]}, l√≠nea {conservar[1]}"
            })
            cambios_por_archivo[archivo].append(linea)
            total_a_eliminar += 1
    
    print(f"‚ö†Ô∏è Se eliminar√°n {total_a_eliminar} entradas duplicadas, conservando la primera ocurrencia de cada una.")
    
    # Paso 4: Realizar las eliminaciones
    archivos_modificados = 0
    lineas_eliminadas = 0
    
    for archivo, lineas_a_eliminar in cambios_por_archivo.items():
        try:
            # Ordenar l√≠neas en orden descendente para eliminar desde el final
            lineas_a_eliminar.sort(reverse=True)
            
            with open(archivo, 'r', encoding='utf-8') as f:
                lineas = f.readlines()
            
            # Eliminar las l√≠neas marcadas (ajustando el √≠ndice porque las l√≠neas comienzan en 1)
            for linea_num in lineas_a_eliminar:
                del lineas[linea_num - 1]
                lineas_eliminadas += 1
            
            # Escribir el archivo actualizado
            with open(archivo, 'w', encoding='utf-8') as f:
                f.writelines(lineas)
            
            archivos_modificados += 1
            
        except Exception as e:
            print(f"[ERROR] Error al modificar el archivo {archivo}: {e}")
    
    # Paso 5: Generar reporte
    ahora = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    nombre_reporte = f"reporte_duplicados_{ahora}.txt"
    
    # Agrupar por archivo para el reporte
    reporte_por_archivo = defaultdict(list)
    for item in reporte:
        reporte_por_archivo[item["archivo"]].append(item)
    
    with open(nombre_reporte, 'w', encoding='utf-8') as f:
        f.write(f"REPORTE DE ELIMINACI√ìN DE DUPLICADOS\n")
        f.write(f"Fecha y hora: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Total de sentencias duplicadas: {len(duplicadas)}\n")
        f.write(f"Total de entradas eliminadas: {lineas_eliminadas}\n")
        f.write(f"Total de archivos modificados: {archivos_modificados}\n\n")
        
        f.write("DETALLE DE ELIMINACIONES POR ARCHIVO:\n")
        f.write("=" * 80 + "\n\n")
        
        for archivo, items in reporte_por_archivo.items():
            f.write(f"ARCHIVO: {archivo}\n")
            f.write("-" * 80 + "\n")
            
            for item in items:
                f.write(f"‚Ä¢ L√≠nea {item['linea']}: {item['contenido']}\n")
                f.write(f"  Conservada en: {item['conservada_en']}\n\n")
            
            f.write("\n")
    
    print(f"\n‚úÖ Proceso completado: {archivos_modificados} archivos modificados, {lineas_eliminadas} l√≠neas eliminadas.")
    print(f"üìù Se ha generado un reporte detallado en: {nombre_reporte}")

if __name__ == "__main__":
    carpeta_actual = os.getcwd()
    eliminar_duplicados_automaticamente(carpeta_actual)
